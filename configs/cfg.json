{
    "ds_to_use": "vg_split",
    "csv_suffix": "qnet",
    "train_balanced_set": true,
    "test_balanced_set": true,
    "test_at_runtime": true,
    "underscore_in_csv": false,
    "do_dist": false,
    "do_dp": true,
    "bs": 16,
    "nw": 4,
    "bsv": 16,
    "nwv": 4,
    "lr": 1e-4,
    "devices": 0,
    "opt_fn": "Adam",
    "opt_fn_params": {
	"betas": [0.9, 0.99]
    },
    "append_rel_vector": false,
    "use_rel": false,
    "test_first": false,
    "test_ent": false,
    "do_norm": false,
    "do_norm_feats": false,
    "do_tfms": false,
    "do_flip": false,
    "use_default_encoder": true,
    "print_query": false,
    "use_same_atb": true,
    "use_model": "retina",
    "use_pret_reg_box": false,
    "resize_img": [300, 300],
    "yolo_stuff": {
	"weights_file": "./weights/official_yolov3_weights_pytorch.pth",
	"model_params": {
	    "backbone_name": "darknet_53",
	    "backbone_pretrained": ""
	},
	"yolo": {
	    "anchors": [[[116, 90], [156, 198], [373, 326]],
			[[30, 61], [62, 45], [59, 119]],
			[[10, 13], [16, 30], [33, 23]]],
	    "classes": 80},
	"we_dim": 256
    },
    "tmp_path": "./tmp",
    "use_multi": true,
    "use_pretrained_model": false,
    "use_focal": true,
    "use_locp": false,
    "use_inv_locp": false,
    "unfreeze_model": false,
    "use_softmax": false,
    "ratios": "[1/2, 1, 2]",
    "scales": "[1, 2**(1/3), 2**(2/3)]",
    "scale_factor": 4,
    "emb_dim": 300,
    "matching_threshold": 0.6,
    "epochs": 10,
    "alpha": 0.25,
    "gamma": 2,
    "use_bidirectional": true,
    "lstm_dim": 128,
    "use_reduce_lr_plateau": true,
    "patience": 2,
    "reduce_factor": 0.1,
    "lamb_reg": 1,
    "lambda_rel": 0.1,
    "resume_path": "",
    "resume": true,
    "load_opt": false,
    "strict_load": false,
    "load_normally": true,
    "test_only": false,
    "valid_also": false,
    "get_predictions": false,
    "acc_iou_threshold": 0.5,
    "use_lang": true,
    "use_img": true,
    "bert_cfg": {
	"attention_probs_dropout_prob": 0.1,
	"hidden_act": "gelu",
	"hidden_dropout_prob": 0.1,
	"hidden_size": 300,
	"initializer_range": 0.02,
	"intermediate_size": 512,
	"max_position_embeddings": 512,
	"num_attention_heads": 12,
	"num_hidden_layers": 12,
	"type_vocab_size": 2,
	"vocab_size": 30522
    }
}
